{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de patrones: Identificación de grupos o Clustering\n",
    "### Ramón Soto C. [(rsotoc@moviquest.com)](mailto:rsotoc@moviquest.com/)\n",
    "![ ](images/blank.png)\n",
    "![agents](images/binary_data_under_a_magnifying.jpg)\n",
    "[ver en nbviewer](http://nbviewer.ipython.org/github/rsotoc/pattern-recognition/blob/master/Clustering%20IV.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Técnicas de clustering: *ISODATA*\n",
    "\n",
    "La técnica de *k-medias* (o *k-means*) es una de las técnicas de clustering más simples y más utilizadas; es una técnica muy simple y rápida. Sin embargo, es fuertemente dependiente de la selección de $k$ y este parámetro no puede modificarse una vez que inicia el proceso. Existen diversos métodos relacionado con $k$-medias que buscan resolver alguna de sus limitantes, entre los que se encuentran $k$-medianas, $k$-medoides, $k$-medias difuso.\n",
    "\n",
    "El método **ISODATA** (*Iterative Self-Organizing Data Analysis Techniques*) es un algoritmo similar al $k$-means; su objetivo es particionar un conjunto de datos en subconjuntos. Sin embargo, a diferencia de $k$-means, el método Isodata maneja una serie de [*heurísticas*](https://en.wikipedia.org/wiki/Heuristic) con tres objetivos:\n",
    "\n",
    "* Eliminar clusters con poco ejemplares.\n",
    "* Unir clusters muy cercanos.\n",
    "* Dividir clusters dispersos\n",
    "\n",
    "![ ](images/isodata-1.png)\n",
    "\n",
    "\n",
    "### Parámetros\n",
    "\n",
    "El algoritmo Isodata utiliza los siguientes parámetros:\n",
    "\n",
    "* $k_{init}$: Número inicial de clusters.\n",
    "* $k$: el número actual de clusters\n",
    "* $n_{min}$: Mínimo número de elementos en un cluster.\n",
    "* $I_{max}$: Máximo número de iteraciones.\n",
    "* $\\sigma_{max}$: Máximo valor de la desviación estándar de los puntos al centro de su cluster, a lo largo de cada eje.\n",
    "* $L_{min}$: Distancia mínima entre los centroides de las clases.\n",
    "* $P_{max}$: Número máximo de clusters que pueden ser unificados en una iteración.\n",
    "\n",
    "\n",
    "### Algoritmo\n",
    "\n",
    "El algoritmo Isodata sigue los siguientes pasos (dado un conjunto de datos):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inicializar el ambiente\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from scipy.spatial import distance\n",
    "np.set_printoptions(precision=2, suppress=True) # Cortar la impresión de decimales a 1\n",
    "\n",
    "os.chdir('Data sets')\n",
    "LARGER_DISTANCE = sys.maxsize\n",
    "TALK = True # TALK = True, imprime resultados parciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                A          B\n",
      "count   30.000000  30.000000\n",
      "mean    62.576333  62.595633\n",
      "std     35.940813  29.057323\n",
      "min      0.000000   0.000000\n",
      "25%     68.720000  57.262500\n",
      "50%     77.345000  75.655000\n",
      "75%     86.000000  83.262750\n",
      "max    100.000000  95.063000\n"
     ]
    }
   ],
   "source": [
    "# Leer los datos de archivo\n",
    "df = pd.read_csv(\"datosProm.csv\", names = ['A', 'B'])\n",
    "print (df.describe())\n",
    "\n",
    "DATA_SET = df.values\n",
    "DATA_LEN = len(DATA_SET)\n",
    "\n",
    "# Definir una clase para expresar puntos y su asignación a un cluster\n",
    "class DataPoint:\n",
    "    def __init__(self, p):\n",
    "        self.value = p[:]\n",
    "        \n",
    "    def set_value(self, p):\n",
    "        self.value = p\n",
    "    \n",
    "    def get_value(self):\n",
    "        return self.value\n",
    "    \n",
    "    def set_cluster(self, cluster):\n",
    "        self.cluster = cluster\n",
    "    \n",
    "    def get_cluster(self):\n",
    "        return self.cluster\n",
    "\n",
    "data = []\n",
    "def initialize_dataset():\n",
    "    for i in range(DATA_LEN):\n",
    "        point = DataPoint(DATA_SET[i])\n",
    "        point.set_cluster(None)\n",
    "        data.append(point)\n",
    "    return\n",
    "\n",
    "# --------------------------\n",
    "# Crear el conjunto de datos\n",
    "initialize_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Definir los valores de $k_{init}, n_{min}, I_{max}, \\sigma_{max}, L_{min}$ y $P_{max}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K_INIT = 5\n",
    "N_MIN = 3\n",
    "I_MAX = 10\n",
    "S_MAX = 5\n",
    "L_MIN = 80\n",
    "P_MAX = 2\n",
    "\n",
    "num_clusters = 5 # valor de k\n",
    "iteration = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Seleccionar arbitrariamente los centroides iniciales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroides inicializados en:\n",
      "[70.280000000000001, 42.125]\n",
      "[0.0, 56.75]\n",
      "[79.0, 2.5]\n",
      "[75.640000000000001, 11.667]\n",
      "[82.0, 58.799999999999997]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir forma de muestreo; 0 = random, 1=head, 2=tail\n",
    "SAMPLING_METHOD = 1 \n",
    "\n",
    "centroids = []\n",
    "def initialize_centroids():\n",
    "    if (TALK) : \n",
    "        print(\"Centroides inicializados en:\")\n",
    "    for c in range(num_clusters):\n",
    "        if (SAMPLING_METHOD == 0) :\n",
    "            which = random.randint(0,DATA_LEN-1)\n",
    "        elif (SAMPLING_METHOD == 1):\n",
    "            which = c\n",
    "        else :\n",
    "            which = DATA_LEN-1 - c\n",
    "                \n",
    "        centroids.append(list(DATA_SET[which]))\n",
    "        if (TALK) : \n",
    "            print(centroids[c])        \n",
    "    if (TALK) : \n",
    "        print()\n",
    "    \n",
    "    return\n",
    "\n",
    "# --------------------------\n",
    "# Inicializar los centroides\n",
    "initialize_centroids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Asignar cada punto del conjunto de datos al cluster donde la distancia del punto al centroide es menor. \n",
    "\n",
    "4) Eliminar los clusters con menos de $n_{min}$ elementos. Ajustar el valor de $k$ y reetiquetar los clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualizando clusters\n",
      "El cluster  0  incluye  2 miembros.\n",
      "El cluster  1  incluye  7 miembros.\n",
      "El cluster  2  incluye  3 miembros.\n",
      "El cluster  3  incluye  2 miembros.\n",
      "El cluster  4  incluye  16 miembros.\n",
      "\n",
      "Eliminando cluster  0\n",
      "Eliminando cluster  3\n",
      "El cluster  0  incluye  0 miembros.\n",
      "El cluster  1  incluye  7 miembros.\n",
      "El cluster  2  incluye  3 miembros.\n",
      "El cluster  3  incluye  0 miembros.\n",
      "El cluster  4  incluye  16 miembros.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "elim = 0\n",
    "members = []\n",
    "def update_clusters():\n",
    "    global num_clusters, elim, members\n",
    "    changed = False\n",
    "    \n",
    "    if (TALK) :\n",
    "        print(\"Actualizando clusters\")\n",
    "    for i in range(DATA_LEN):\n",
    "        minDistance = LARGER_DISTANCE\n",
    "        currentCluster = 0\n",
    "        \n",
    "        for j in range(num_clusters):\n",
    "            dist = distance.euclidean(data[i].get_value(), centroids[j])\n",
    "            if(dist < minDistance):\n",
    "                minDistance = dist\n",
    "                currentCluster = j\n",
    "        \n",
    "        if(data[i].get_cluster() is None or data[i].get_cluster() != currentCluster):\n",
    "            data[i].set_cluster(currentCluster)\n",
    "            changed = True\n",
    "            \n",
    "    members = [0] * num_clusters\n",
    "    for i in range(DATA_LEN):\n",
    "        members[data[i].get_cluster()] += 1\n",
    "    \n",
    "    if (TALK) : \n",
    "        for j in range(num_clusters):\n",
    "            print(\"El cluster \", j, \" incluye \", members[j], \"miembros.\")\n",
    "        print()\n",
    "        \n",
    "    elim = 0\n",
    "    for j in range(num_clusters):\n",
    "        if (members[j] < N_MIN):\n",
    "            if (TALK) :\n",
    "                print(\"Eliminando cluster \", j)\n",
    "            for i in range(DATA_LEN):\n",
    "                cluster = data[i].get_cluster()\n",
    "                if (cluster == j-elim) :\n",
    "                    data[i].set_cluster(None)\n",
    "                elif (cluster != None and cluster > j-elim) :\n",
    "                    data[i].set_cluster(cluster-1)\n",
    "            elim += 1\n",
    "            members[j] = 0\n",
    "    \n",
    "    if (TALK and elim > 0) : \n",
    "        for j in range(num_clusters):\n",
    "            print(\"El cluster \", j, \" incluye \", members[j], \"miembros.\")\n",
    "        print()\n",
    "    num_clusters -= elim\n",
    "\n",
    "    return changed\n",
    "\n",
    "# --------------------------\n",
    "# Actualizar los clusters\n",
    "KEEP_WALKING = update_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Recalcular los centroides a partir de los puntos actualmente en cada cluster. Si se eliminaron clusters en el paso 4) el algoritmo regresa la paso 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los nuevos centroids son:\n",
      "[0.0, 73.886571428571415]\n",
      "[88.90666666666668, 2.5]\n",
      "[82.259999999999991, 78.200249999999983]\n",
      "\n",
      "Actualizando clusters\n",
      "El cluster  0  incluye  7 miembros.\n",
      "El cluster  1  incluye  6 miembros.\n",
      "El cluster  2  incluye  17 miembros.\n",
      "\n",
      "Los nuevos centroids son:\n",
      "[0.0, 73.886571428571415]\n",
      "[81.808333333333323, 11.222333333333333]\n",
      "[81.555294117647065, 76.078176470588218]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def update_centroids():\n",
    "    global centroids\n",
    "    centroids = []\n",
    "\n",
    "    if (TALK) : \n",
    "        print(\"Los nuevos centroids son:\")\n",
    "    for j in range(num_clusters):\n",
    "        means = [0] * DATA_SET.shape[1]\n",
    "            \n",
    "        clusterSize = 0\n",
    "        for k in range(len(data)):\n",
    "            if(data[k].get_cluster() == j):\n",
    "                p = data[k].get_value()\n",
    "                for i in range(DATA_SET.shape[1]):\n",
    "                    means[i] += p[i]\n",
    "                clusterSize += 1\n",
    "\n",
    "        if(clusterSize > 0):\n",
    "            for i in range(DATA_SET.shape[1]):\n",
    "                means[i] = means[i] / clusterSize\n",
    "            centroids.append(means)\n",
    "\n",
    "        if (TALK) : \n",
    "            print(centroids[j])        \n",
    "    if (TALK) : \n",
    "        print()\n",
    "    \n",
    "    return\n",
    "\n",
    "# --------------------------\n",
    "# Actualizar los centroides\n",
    "update_centroids()\n",
    "if (elim > 0) :\n",
    "    KEEP_WALKING = update_clusters()\n",
    "    update_centroids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Calcular las distancias promedio $\\Delta_j$ de los puntos de un cluster a su centroide y la distancia promedio general $\\Delta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distancia promedio en el cluster 0: 8.882897959183678\n",
      "Distancia promedio en el cluster 1: 12.762142305287727\n",
      "Distancia promedio en el cluster 2: 13.744777384565223\n",
      "Distancia promedio global: 12.413811836120695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deltas = []\n",
    "delta = 0\n",
    "def update_deltas():\n",
    "    global deltas, delta\n",
    "    deltas = [0] * num_clusters\n",
    "    delta = 0\n",
    "    \n",
    "    for i in range(DATA_LEN):\n",
    "        cluster = data[i].get_cluster()\n",
    "        deltas[cluster] += distance.euclidean(data[i].get_value(), centroids[cluster])\n",
    "    mem = 0\n",
    "    for i in range(num_clusters):\n",
    "        delta += deltas[i]\n",
    "        mem += members[i]\n",
    "        deltas[i] /= members[i]\n",
    "        if (TALK) : \n",
    "            print(\"Distancia promedio en el cluster {}:\".format(i), deltas[i])        \n",
    "    delta /= mem\n",
    "    if (TALK) : \n",
    "        print(\"Distancia promedio global: {}\\n\".format(delta))\n",
    "    \n",
    "    return\n",
    "    \n",
    "update_deltas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Si esta es la última iteración, terminar. En caso contrario verificar si quedan la mitad o menos de los clusters iniciales y de ser así ir al paso 8 (dividir clusters). En caso contrario, si la iteración es par o el número de clusters es mayor que el doble de los clusters iniciales, entonces ir al paso 9 (unir). En caso contrario, volver al paso 3 (como $k$-means)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ejecutar sólo desués de haber \"activado\" los pasos 8 y 9\n",
    "#while(iteration < I_MAX and KEEP_WALKING) :\n",
    "#    if (num_clusters <= K_INIT / 2) :\n",
    "#        divide_clusters()\n",
    "#    elif (iteration % 2 == 0 or num_clusters > 2 * K_INIT) :\n",
    "#        mix_clusters()\n",
    "#        \n",
    "#    KEEP_WALKING = update_clusters()\n",
    "#    if (KEEP_WALKING):\n",
    "#        update_centroids()\n",
    "#    else :\n",
    "#        if (TALK) : \n",
    "#            print (\"No más cambios.\")\n",
    "#    iteration += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Calcular, para cada cluster $S_j$ un vector $\\mathbf{s_j} = (s_{j1}\\ldots s_{jn_j})$ con las desviaciones estándar $s_{ji}$ de cada atributo $i$ de los elementos $\\mathbf{x} = (x_{1}\\ldots x_{n_j})$ en el cluster (con respecto al centroide $\\mathbf{z}_j$).\n",
    "\n",
    "$$s_{ji}=\\frac{1}{n_j}\\sqrt{\\sum_{\\mathbf{x}\\in S} (x_i-z_{ji})^2 }$$\n",
    "\n",
    "Si al menos una componente del vector de desviaciones estándar sobrepasa la máxima desviación estándar permitida, $\\sigma_{max}$ consideramos dividir la clase, siempre que se cumpla alguna de las siguientes condiciones adicionales:\n",
    "\n",
    "* Que la distancia promedio entre puntos en el cluster sea mayor que la distancia promedio global y que el cluster tenga más del doble de elementos que el mínimo permitido para un cluster ($n_{min}$), o\n",
    "\n",
    "* Que el número actual de clusters sea menor que la mitad del número de clusters inicial.\n",
    "\n",
    "Si se cumple alguna de estas condiciones, reemplazar el cluster por dos nuevos clusters. Seleccionar como centroides de estos clusters los dos vectores más alejados entre sí en el cluster original.\n",
    "\n",
    "Si hubo al menos una división de clusters, volver a reconstruir todos los clusters (y centroides)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se dividirá el cluster 1.\n",
      "Se crearán nuevos clusters en [91.719999999999999, 0.0] y [70.799999999999997, 35.0].\n",
      "\n",
      "Actualizando clusters\n",
      "El cluster  0  incluye  7 miembros.\n",
      "El cluster  1  incluye  16 miembros.\n",
      "El cluster  2  incluye  5 miembros.\n",
      "El cluster  3  incluye  2 miembros.\n",
      "\n",
      "Eliminando cluster  3\n",
      "El cluster  0  incluye  7 miembros.\n",
      "El cluster  1  incluye  16 miembros.\n",
      "El cluster  2  incluye  5 miembros.\n",
      "El cluster  3  incluye  0 miembros.\n",
      "\n",
      "Los nuevos centroids son:\n",
      "[0.0, 73.886571428571415]\n",
      "[82.259999999999991, 78.200249999999983]\n",
      "[84.009999999999991, 6.466800000000001]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def divide_clusters():\n",
    "    global num_clusters\n",
    "    # Cálculo de desviaciones estandar\n",
    "    sigma_vect = [[0] * DATA_SET.shape[1]] * num_clusters\n",
    "    for d in range(DATA_LEN):\n",
    "        cluster = data[d].get_cluster()\n",
    "        p = data[d].get_value()\n",
    "        for i in range(DATA_SET.shape[1]):\n",
    "            sigma_vect[cluster][i] += (p[i] - centroids[cluster][i])**2        \n",
    "    candidates = []\n",
    "    for cluster in range(num_clusters):\n",
    "        for i in range(DATA_SET.shape[1]):\n",
    "            sigma_vect[cluster][i] = math.sqrt(sigma_vect[cluster][i]) / members[cluster]\n",
    "            if (sigma_vect[cluster][i] > S_MAX):\n",
    "                candidates.append(cluster)\n",
    "                break # Sucio... pero eficiente :-)\n",
    "    \n",
    "    divided = False\n",
    "    for cluster in candidates:\n",
    "        cond = num_clusters < K_INIT/2 or (deltas[cluster] > delta and members[cluster] > N_MIN)\n",
    "        if(cond) :\n",
    "            centroids.pop(cluster)\n",
    "            points = []\n",
    "            for d in range(DATA_LEN):\n",
    "                if (data[d].get_cluster() == cluster):\n",
    "                    points.append(data[d].get_value())\n",
    "            dist = distance.squareform(distance.pdist(points, 'euclidean'))\n",
    "            idx = (dist==dist.max()).argmax()\n",
    "            z1 = list(points[idx // len(points)])\n",
    "            z2 = list(points[idx % len(points)])\n",
    "            if (TALK) :\n",
    "                print(\"Se dividirá el cluster {}.\\nSe crearán nuevos clusters en {} y {}.\\n\"\n",
    "                     .format(cluster, z1, z2))\n",
    "            centroids.append(z1)\n",
    "            centroids.append(z2)\n",
    "            num_clusters += 1\n",
    "            divided = True\n",
    "\n",
    "    if (divided) :\n",
    "        update_clusters()\n",
    "        update_centroids()\n",
    "    \n",
    "    return \n",
    "\n",
    "divide_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Calcular las distancias *inter-clusters* entre todos los centroides de los clusters. Seleccionar el máximo número permitido de pares de clusters para ser unificados ($P_{max}$), que satisfagan las siguientes condiciones:\n",
    "\n",
    "* Que la distancia entre los centroides sea menor que la mínima distancia permitida ($L_{min}$), y\n",
    "\n",
    "* Que ninguno de los dos clusters haya participado en una unificación en la presente iteración.\n",
    "\n",
    "Si se cumplen estas condiciones, reemplazar los dos cluster por un nuevo cluster cuyo centroide es el punto medio de los centroides originales.\n",
    "\n",
    "Si hubo al menos una unificación de clusters, volver a reconstruir todos los clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unificando clusters 1 y 2\n",
      "Se creará nuevo centroide en [83.134999999999991, 42.333524999999995]\n",
      "\n",
      "Actualizando clusters\n",
      "El cluster  0  incluye  7 miembros.\n",
      "El cluster  1  incluye  23 miembros.\n",
      "\n",
      "Los nuevos centroids son:\n",
      "[0.0, 73.886571428571415]\n",
      "[81.621304347826069, 59.159260869565216]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def mix_clusters():\n",
    "    global centroids, num_clusters\n",
    "    dist = distance.squareform(distance.pdist(centroids, 'euclidean'))\n",
    "    flag = math.floor(dist.max() * 10)\n",
    "    dist[dist == 0] = flag\n",
    "    \n",
    "    mixed = False\n",
    "    while (dist.min() < flag):\n",
    "        idx = (dist==dist.min()).argmax()\n",
    "        z1 = idx // len(centroids)\n",
    "        z2 = idx % len(centroids)\n",
    "        \n",
    "        if (dist.min() < L_MIN):\n",
    "            dist[z1] = flag\n",
    "            dist[:,z1] = flag\n",
    "            dist[z2] = flag\n",
    "            dist[:,z2] = flag\n",
    "            z = [sum(x)/2 for x in zip(centroids[z1], centroids[z2])]\n",
    "            centroids[z1] = z\n",
    "            centroids[z2] = [LARGER_DISTANCE]*DATA_SET.shape[1]\n",
    "            num_clusters -= 1\n",
    "\n",
    "            mixed = True\n",
    "            if(TALK):\n",
    "                print(\"Unificando clusters {} y {}\\nSe creará nuevo centroide en {}\\n\"\n",
    "                      .format(z1, z2, z))\n",
    "        else :\n",
    "            dist[z1][z2] = flag\n",
    "            dist[z2][z1] = flag\n",
    "        \n",
    "    if (mixed) :\n",
    "        update_clusters()\n",
    "        update_centroids()\n",
    "\n",
    "    return\n",
    "\n",
    "mix_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se dividirá el cluster 0.\n",
      "Se crearán nuevos clusters en [0.0, 56.75] y [0.0, 90.625].\n",
      "\n",
      "Se dividirá el cluster 1.\n",
      "Se crearán nuevos clusters en [91.719999999999999, 0.0] y [100.0, 95.062999999999988].\n",
      "\n",
      "Actualizando clusters\n",
      "El cluster  0  incluye  12 miembros.\n",
      "El cluster  1  incluye  7 miembros.\n",
      "El cluster  2  incluye  5 miembros.\n",
      "El cluster  3  incluye  6 miembros.\n",
      "\n",
      "Los nuevos centroids son:\n",
      "[79.186666666666667, 66.520416666666662]\n",
      "[0.0, 73.886571428571415]\n",
      "[84.009999999999991, 6.466800000000001]\n",
      "[84.5, 88.347333333333324]\n",
      "\n",
      "Actualizando clusters\n",
      "El cluster  0  incluye  7 miembros.\n",
      "El cluster  1  incluye  7 miembros.\n",
      "El cluster  2  incluye  6 miembros.\n",
      "El cluster  3  incluye  10 miembros.\n",
      "\n",
      "Los nuevos centroids son:\n",
      "[80.997142857142862, 62.769571428571432]\n",
      "[0.0, 73.886571428571415]\n",
      "[81.808333333333323, 11.222333333333333]\n",
      "[81.945999999999998, 85.394199999999984]\n",
      "\n",
      "Unificando clusters 0 y 3\n",
      "Se creará nuevo centroide en [81.471571428571423, 74.081885714285704]\n",
      "\n",
      "Actualizando clusters\n",
      "El cluster  0  incluye  16 miembros.\n",
      "El cluster  1  incluye  7 miembros.\n",
      "El cluster  2  incluye  7 miembros.\n",
      "\n",
      "Los nuevos centroids son:\n",
      "[82.259999999999991, 78.200249999999983]\n",
      "[0.0, 73.886571428571415]\n",
      "[80.161428571428573, 15.637]\n",
      "\n",
      "Actualizando clusters\n",
      "El cluster  0  incluye  16 miembros.\n",
      "El cluster  1  incluye  7 miembros.\n",
      "El cluster  2  incluye  7 miembros.\n",
      "\n",
      "No más cambios.\n"
     ]
    }
   ],
   "source": [
    "# Reproducido aquí para facilitar la ejecución\n",
    "iteration +=1\n",
    "while(iteration < I_MAX and KEEP_WALKING) :\n",
    "    if (num_clusters <= K_INIT / 2) :\n",
    "        divide_clusters()\n",
    "    elif (iteration % 2 == 0 or num_clusters > 2 * K_INIT) :\n",
    "        mix_clusters()\n",
    "        \n",
    "    KEEP_WALKING = update_clusters()\n",
    "    if (KEEP_WALKING):\n",
    "        update_centroids()\n",
    "    else :\n",
    "        if (TALK) : \n",
    "            print (\"No más cambios.\")\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método ISODATA es un método poco utilizado fuera del área de procesamiento de imágenes. Es difícil de configurar, por la cantidad y naturaleza de los parámetros a definir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width: 3px;\">\n",
    "\n",
    "### Tarea 6\n",
    "\n",
    "* Generar un programa integrado del método ISODATA \n",
    "\n",
    "* Aplicar los elementos vistos en clase hasta el momento a un conjunto de datos de su preferencia\n",
    "\n",
    "**Fecha de entrega**: Martes 20 de septiembre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
